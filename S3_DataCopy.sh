#!/bin/bash
#=======================================================================================================================
# Script name   : S3_DataCopy.sh
# Date Created  : 04/12/2016
# Author        : Kiran Anand
# Description   : Script to Start/Stop AWS instances
# OS            : Linux (Red Hat)
# Shell         : Bash
# Command       : S3_DataCopy.sh <option (backup/restore) FS-list-provided (optional parameter - y/n -> default 'n')>
# Prerequisites : The user executing the script should have the following.
#			1) AWS CLI installed in the local machine executing the script.
#			2) Setup AWS CLI environment variables in ~/.aws directory - If not include those in the script.
#			3) The user executing should be able to run AWS CLI executable "aws".
#			4) Write access to the Present Working Directory ($PWD) as well as S3 bucket.
#			5) Choose one of the options for executing the script as listed below.
#			5a) If FS-list-provided is set to 'y', file fs_list.txt (predefined list of filesystems) is present in $PWD.
#			5b) If FS-list-provided is not set to 'y', the file fs_list.txt will be generated by the script.
# Dependency    : fs_list.txt file if the argument FS-list-provided is set to 'y' -> option 5a is chosen.
# Other Remarks : Necessary comments are provided in the script inline.
#
# 				  If option 5a is chosen, all filesystems to be backed-up/restored should be provided in fs_list.txt -
#				  Each filesystem within fs_list.txt should be separated by newline character.
#
# 				  If option 5b is chosen, the fs_list.txt will be generated by the script -
# 				  All disks within the instance except the one used for root mount (/) will be considered as ephemeral
#----------------------------------------------------------------------------------------------------------------------
# Change log:
#
#    Date       Updated by      Ver.    Description
#  ----------  -------------  -------  --------------------------------------------------------------------------------
#  04-12-2016  Kiran Anand      1.0     Initial write
#
#=======================================================================================================================

### Set AWS environment variables - If these are not set in the AWS CLI or want to use a different access id
##export AWS_ACCESS_KEY_ID = 
##export AWS_SECRET_ACCESS_KEY =
##export AWS_DEFAULT_REGION = 

### Function to display usage
function display_usage
{
	echo "Usage: S3_DataCopy.sh <option (backup/restore) FS-list-provided (optional parameter - y/n -> default 'n')>"
	echo "Option switch to used to copy local data to S3 - backup"
	echo "Option switch  to be used to copy data from S3 to local filesystems - restore"
	echo "The second parameter, FS-list-provided is an optional (y/n) parameter, default value is 'n'"
	echo "If the second parameter is passed in as 'y', an input file fs_list.txt is required in the same directory as the script"
	echo "This input file should contain a list of all filesystems to be backed-up/restored separated by a newline character"
	echo "A list of all the filesystems created on instance-store devices is expected in this file"
}

### Initialize arguments passed and local variables
if [ $# -ge 1 ]; then
	option=$1
fi

### Edit the following variables with proper S3 bucket information
s3baseurl=s3://kiran-test/testFolder
s3dir=Dnode1
##
fslist='n'
file=$PWD/fs_list.txt

logfile=$PWD/S3_DataCopy${option}.log
rm -f $PWD/S3_DataCopy${option}.log

### If the second argument is not set to 'y', generate the fs_list.txt
if [ $# -eq 1 ]; then
	echo "No filesystems list passed in" >> ${logfile}
	echo "Generating the list of filesystems created on instance-store devices" >> ${logfile}

	### Find all available disks other than the one used for root mount point
	### Crude way of avoiding root mount point but works on AWS instances
	rm -f dev_fs_map.txt
	rootmnt=`df -h | awk '{print $1 " " $6 ":"}' | grep "/:" | awk -F "/" '{print $3}'`
	echo ${rootmnt} > dev_fs_map.txt
	rootblkdev=`echo ${rootmnt} | rev | cut -c 2- | rev`
	echo ${rootblkdev} >> dev_fs_map.txt
	lsblk -d -n -f | grep -v ${rootblkdev} | awk '{print $1 " " $4}' >> dev_fs_map.txt
	lsblk -d -n -f | grep -v ${rootblkdev} | awk '{print $4}' > fs_list.txt
	##
elif [ $# -eq 2 ]; then
	fslist=$2
	if [ ${fslist} == y ]; then
		echo "Filesystems list present in -> ${file}" >> ${logfile}
	else
		echo "Wrong arguments passed..!" >> ${logfile}
		display_usage >> ${logfile}
		exit 1
else
	echo "Wrong number of arguments passed..!" >> ${logfile}
	display_usage >> ${logfile}
	exit 1
fi

### Check if the Filesystems list is present, if not exit 
if [ ! -f ${file} ]; then
	echo "List of filesystems not found - ${file}" >> ${logfile}
	exit 1
fi

### Execute the S3 copy commands using AWS CLI commands
for fs in `cat ${file}`
do
	if [ ${option} == backup ]; then
		echo "Backing up ACLs for - ${fs}" >> ${logfile}
		cd ${fs}
		dir=$(basename${fs})
		getfacl -R . > perm_${dir}.facl
		cd -
		echo "Copying data from Local drives to S3 at - ${instids}" >> ${logfile}
		aws s3 cp --recursive ${fs} ${s3baseurl}/${s3dir}/${fs}
	elif [ ${option} == restore ]; then
		echo "Copying data from S3 to Local drives from - ${instids}" >> ${logfile}
	 	aws s3 cp --recursive ${s3baseurl}/${s3dir}/${fs} ${fs}
	 	echo "Restoring ACLs for - ${fs}" >> ${logfile}
	 	cd ${fs}
		dir=$(basename${fs})
		setfacl --restore=perm_${dir}.facl
		cd -
	else
		echo "Wrong command passed - ${option}" >> ${logfile}
		display_usage >> ${logfile}
		exit 1
	fi
done

exit
